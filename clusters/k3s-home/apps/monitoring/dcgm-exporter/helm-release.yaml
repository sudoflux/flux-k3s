apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: dcgm-exporter
  namespace: monitoring
spec:
  interval: 15m
  chart:
    spec:
      chart: dcgm-exporter
      version: "3.1.5"
      sourceRef:
        kind: HelmRepository
        name: nvidia-dcgm
        namespace: flux-system
  values:
    # Only run on nodes with NVIDIA GPUs
    nodeSelector:
      kubernetes.io/hostname: k3s3
    
    # Use nvidia runtime for GPU access
    runtimeClassName: nvidia
    
    # Resource limits - increased CPU for initialization
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 500m
        memory: 256Mi
    
    # Service configuration
    service:
      type: ClusterIP
      port: 9400
      targetPort: 9400
      name: metrics
    
    # Arguments for the exporter
    arguments:
      - "-f"
      - "/etc/dcgm-exporter/dcp-metrics-included.csv"
    
    # Health probe configuration for proper startup handling
    livenessProbe:
      httpGet:
        path: /health
        port: 9400
      initialDelaySeconds: 60  # Longer delay for GPU initialization
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
    
    readinessProbe:
      httpGet:
        path: /health
        port: 9400
      initialDelaySeconds: 45  # Allow time for DCGM to fully initialize
      periodSeconds: 15
      timeoutSeconds: 5
      failureThreshold: 2
      successThreshold: 1
    
    # ServiceMonitor for Prometheus scraping
    serviceMonitor:
      enabled: true
      interval: 15s
      additionalLabels:
        release: kube-prometheus-stack
    
    # Security context - temporarily re-adding privileged mode to debug
    securityContext:
      privileged: true
      capabilities:
        add:
          - SYS_ADMIN
      runAsNonRoot: false
      runAsUser: 0
    
    # Environment variables for NVIDIA libraries
    extraEnv:
      - name: NVIDIA_DRIVER_CAPABILITIES
        value: "utility"
      - name: NVIDIA_VISIBLE_DEVICES
        value: "all"